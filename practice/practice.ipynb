{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, lxml, os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "headers = {\n",
    "            'User-agent':\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36\"\n",
    "            }\n",
    "\n",
    "phrase= 'nlp'\n",
    "\n",
    "params = {\"q\": phrase, \"hl\": \"en\"}\n",
    "html = requests.get('https://scholar.google.com/scholar', headers=headers, params=params).text\n",
    "soup = BeautifulSoup(html, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('#gs_ri')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the terms: \n",
    "each term will have its size in the circle\n",
    "each combination of terms will have a connection between the nodes and the thickness will show the conjunction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(phrases:list) -> dict:\n",
    "\n",
    "    dict_ = {}\n",
    "\n",
    "    \n",
    "\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(results_list:list) -> str:\n",
    "\n",
    "    result_num = 0\n",
    "    \n",
    "    for term in results_list:\n",
    "        if re.findall('about', term.lower()):\n",
    "            result_num = re.findall('about (.*) results', term.lower())[0]\n",
    "            result_num = re.sub(',', '', result_num)\n",
    "            result_num = int(result_num)\n",
    "\n",
    "    return result_num\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_number_of_results(phrase:str)->int:\n",
    "\n",
    "    \n",
    "    params = {\"q\": phrase, \"hl\": \"en\"}\n",
    "    html = requests.get('https://scholar.google.com/scholar', headers=headers, params=params).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "        \n",
    "    # the dictionary will be collected here\n",
    "    results_list = []\n",
    "\n",
    "    # Container where all needed dict_ is located\n",
    "    for result in soup.select('.gs_ab_mdw'):\n",
    "        results_list.append(result.text)\n",
    "\n",
    "    result_num = extract_number(results_list)\n",
    "    \n",
    "    return result_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\"q\": 'nlp and healthcare', \"hl\": \"en\"}\n",
    "html = requests.get('https://scholar.google.com/scholar', headers=headers, params=params).text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    \n",
    "# the dictionary will be collected here\n",
    "results_list = []\n",
    "\n",
    "# Container where all needed dict_ is located\n",
    "for result in soup.select('.gs_ab_mdw'):\n",
    "    print(result.text)\n",
    "    results_list.append(result.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_phrases(phrases:list)->list:\n",
    "    \"\"\"\n",
    "    gets all phrases and creates a list of their combination \n",
    "    a list of str(phrase 1 + \" AND \" + phrase 2)\n",
    "    \"\"\"\n",
    "    list_of_phrase_comb = []\n",
    "    # combination of terms\n",
    "    for i in range(len(phrases)):\n",
    "        for j in range(len(phrases)):\n",
    "            if i>j:\n",
    "                new_phrase = phrases[i] + \" AND \" + phrases[j]\n",
    "                list_of_phrase_comb.append(new_phrase)\n",
    "\n",
    "    return list_of_phrase_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_node_size(phrases:list) -> dict:\n",
    "    \"\"\"\n",
    "    get the list of phrases\n",
    "    output a dictionary of their size (number of search results for each phrase)\n",
    "    \"\"\"\n",
    "    sizes_dict = {}\n",
    "    # single term search for size of node\n",
    "    for phrase in phrases:\n",
    "        sizes_dict[phrase] = scrape_number_of_results(phrase)\n",
    "        \n",
    "    return sizes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(phrases):\n",
    "    \n",
    "    graph_ = {'nodes':[], 'links':[]}\n",
    "    \n",
    "    sizes_dict =  determine_node_size(phrases)\n",
    "\n",
    "    \n",
    "    # for nodes\n",
    "    # {'nodes' : [{'id': , 'group':2 , 'size':name_freq[char]}]}\n",
    "    for term, numb_ in sizes_dict.items():\n",
    "        graph_['nodes'].append({'id': term, 'group': 1, \"size\":float(np.log(numb_)) })\n",
    "    \n",
    "    list_of_phrase_comb = []\n",
    "    # combination of terms\n",
    "    for i in range(len(phrases)):\n",
    "        for j in range(len(phrases)):\n",
    "            if i>j:\n",
    "                new_phrase = \"\\\"\" + phrases[i] + \"\\\"\" + \" AND \" + \"\\\"\" + phrases[j] + \"\\\"\"\n",
    "                print(new_phrase)\n",
    "                results_num = scrape_number_of_results(phrase=new_phrase)\n",
    "\n",
    "                graph_['links'].append({'source': phrases[i], \n",
    "                                        'target': phrases[j],\n",
    "                                        'value': float(results_num), \n",
    "                                        'color': float(results_num)})\n",
    "    \n",
    "    \n",
    "    return graph_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitra\\AppData\\Local\\Temp\\ipykernel_20564\\2097357067.py:11: RuntimeWarning: divide by zero encountered in log\n",
      "  graph_['nodes'].append({'id': term, 'group': 1, \"size\":float(np.log(numb_)) })\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"decision support systems\" AND \"natural language processing\"\n",
      "\"clinical setting\" AND \"natural language processing\"\n",
      "\"clinical setting\" AND \"decision support systems\"\n",
      "\"artificial intelligence\" AND \"natural language processing\"\n",
      "\"artificial intelligence\" AND \"decision support systems\"\n",
      "\"artificial intelligence\" AND \"clinical setting\"\n",
      "\"healthcare\" AND \"natural language processing\"\n",
      "\"healthcare\" AND \"decision support systems\"\n",
      "\"healthcare\" AND \"clinical setting\"\n",
      "\"healthcare\" AND \"artificial intelligence\"\n"
     ]
    }
   ],
   "source": [
    "graph_ = create_graph(phrases=['natural language processing', 'decision support systems', 'clinical setting', 'artificial intelligence' , 'healthcare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodes': [{'id': 'natural language processing', 'group': 1, 'size': -inf}, {'id': 'decision support systems', 'group': 1, 'size': -inf}, {'id': 'clinical setting', 'group': 1, 'size': -inf}, {'id': 'artificial intelligence', 'group': 1, 'size': -inf}, {'id': 'healthcare', 'group': 1, 'size': -inf}], 'links': [{'source': 'decision support systems', 'target': 'natural language processing', 'value': 0.0, 'color': 0.0}, {'source': 'clinical setting', 'target': 'natural language processing', 'value': 0.0, 'color': 0.0}, {'source': 'clinical setting', 'target': 'decision support systems', 'value': 0.0, 'color': 0.0}, {'source': 'artificial intelligence', 'target': 'natural language processing', 'value': 0.0, 'color': 0.0}, {'source': 'artificial intelligence', 'target': 'decision support systems', 'value': 0.0, 'color': 0.0}, {'source': 'artificial intelligence', 'target': 'clinical setting', 'value': 0.0, 'color': 0.0}, {'source': 'healthcare', 'target': 'natural language processing', 'value': 0.0, 'color': 0.0}, {'source': 'healthcare', 'target': 'decision support systems', 'value': 0.0, 'color': 0.0}, {'source': 'healthcare', 'target': 'clinical setting', 'value': 0.0, 'color': 0.0}, {'source': 'healthcare', 'target': 'artificial intelligence', 'value': 0.0, 'color': 0.0}]}\n"
     ]
    }
   ],
   "source": [
    "print(graph_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "with open(f\"C:\\\\Users\\\\mitra\\\\PassivePy\\\\PassivePyCode\\\\SENG Scrape\\\\graph_{i}.json\", 'w') as fp:\n",
    "    json.dump(graph_, fp)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add something that can plot terms versus time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def matrix_to_edge(self, cooccurrence_matrix:np.matrix, cooccurrence_matrix_with_senti:np.matrix,\n",
    "     pop_names_df:pd.DataFrame, top_n_popular_names:list)->Graph:\n",
    "\n",
    "        graph_ = {'nodes':[], 'links':[]}\n",
    "        shape = cooccurrence_matrix.shape[0]\n",
    "        name_freq = pop_names_df.sum()\n",
    "\n",
    "\n",
    "        # for nodes\n",
    "        # {'nodes' : [{'id': , 'group':2 , 'size':name_freq[char]}]}\n",
    "        for char in top_n_popular_names:\n",
    "            graph_['nodes'].append({'id': char, 'group': 1, \"size\":np.float(np.log(name_freq)[char])*5 })\n",
    "\n",
    "\n",
    "        # for edges\n",
    "        # {'links' : [{'source': , 'target': , 'value': , 'color': }]}\n",
    "        for i in range(shape):\n",
    "            for j in range(shape):\n",
    "                if i>j:\n",
    "                    graph_['links'].append({'source': top_n_popular_names[i], \n",
    "                                            'target': top_n_popular_names[j],\n",
    "                                        'value': np.float(cooccurrence_matrix[i, j]), \n",
    "                                        'color':cooccurrence_matrix_with_senti[i,j]})\n",
    "                    \n",
    "        return graph_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39200\n"
     ]
    }
   ],
   "source": [
    "for term in results_list:\n",
    "    if re.findall('about', term.lower()):\n",
    "        result_num = re.findall('about (.*) results', term.lower())[0]\n",
    "        result_num = re.sub(',', '', result_num)\n",
    "        result_num = int(result_num)\n",
    "        print(result_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['about']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"about\", \"About 39,200 results (0.03 sec)\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adfccd5c958d70cd78f22c942a5f90dd259f52bf203482d766a0ca6ec5e2e798"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
